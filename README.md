# ğŸ§¬ OntoRAG

**Ontology-Augmented Retrieval for Named Entity Linking (NEL)**

OntoRAG is a hybrid retrieval-augmented generation (RAG) pipeline for linking free-text mentions (e.g., food ingredients, chemicals) to ontology terms. It combines lexical and semantic search with LLM-based selection and confidence scoring to achieve accurate entity linking.

---

## âœ¨ Features

- **Hybrid Retrieval** â€” Combines [Whoosh](https://whoosh.readthedocs.io/) lexical search and [FAISS](https://github.com/facebookresearch/faiss) vector search for comprehensive candidate retrieval
- **LLM-Powered Selection** â€” Uses structured prompts with Gemini or local models (Ollama, Hugging Face) to select the best ontology match
- **Confidence Scoring** â€” Evaluates match quality and suggests alternatives when confidence is low
- **Adaptive Retry Logic** â€” Automatically generates synonyms and retries when initial matches are uncertain
- **Multi-Ontology Support** â€” Pre-configured for [FoodOn](https://foodon.org/) with extensible architecture for ChEBI, MEDIC, and others
- **Evaluation Suite** â€” Built-in benchmarking against CRAFT and other gold-standard datasets

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RAG Pipeline                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Query â”€â”€â–º HybridRetriever â”€â”€â–º Selector â”€â”€â–º ConfidenceScorer   â”‚
â”‚                 â”‚                   â”‚              â”‚            â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”             â”‚              â–¼            â”‚
â”‚           â”‚           â”‚             â”‚         Score < 0.6?      â”‚
â”‚        Whoosh      FAISS            â”‚              â”‚            â”‚
â”‚        (lexical)  (vector)          â”‚              â–¼            â”‚
â”‚                                     â”‚     SynonymGenerator      â”‚
â”‚                                     â”‚              â”‚            â”‚
â”‚                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚                                                    â–¼            â”‚
â”‚                                               Best Match        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
onto_rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline.py              # Main RAG pipeline orchestration
â”‚   â”œâ”€â”€ config.py                # Configuration and model settings
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ retriever.py         # HybridRetriever (Whoosh + FAISS)
â”‚   â”‚   â”œâ”€â”€ selector.py          # LLM-based candidate selection
â”‚   â”‚   â”œâ”€â”€ scorer.py            # Confidence scoring
â”‚   â”‚   â”œâ”€â”€ synonyms.py          # Query expansion via synonym generation
â”‚   â”‚   â””â”€â”€ faiss_store.py       # FAISS vector store wrapper
â”‚   â”œâ”€â”€ evaluation/              # Benchmark scripts (CRAFT, OpenFoodFacts)
â”‚   â””â”€â”€ utils/                   # Caching, logging, token tracking
â”œâ”€â”€ prompts/                     # Jinja2 prompt templates
â”‚   â”œâ”€â”€ strict_selection_minimal.tpl
â”‚   â”œâ”€â”€ confidence_assessment3.tpl
â”‚   â””â”€â”€ synonym_generation.tpl
â”œâ”€â”€ data/                        # Ontology dumps, indexes (gitignored)
â”œâ”€â”€ ontologies/                  # OWL files (gitignored)
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <repository-url>
cd onto_rag

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration

Copy the example environment file and add your API keys:

```bash
cp .env.example .env
```

Edit `.env` with your credentials:

```env
GEMINI_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here    # Optional
PINECONE_API_KEY=your_pinecone_api_key     # Optional
```

### 3. Prepare Data

Place your ontology files (e.g., `foodon.owl`) in the `ontologies/` directory, then run the indexing scripts to generate:

- Ontology JSON dumps in `data/`
- Whoosh lexical indexes
- FAISS vector indexes

### 4. Usage

```python
import asyncio
from src.pipeline import create_pipeline

async def main():
    pipeline = create_pipeline(provider="gemini")
    
    result, candidates = await pipeline.run(
        query="organic raw milk",
        context="Found in ingredient list of artisan cheese"
    )
    
    print(f"Matched: {result['label']} ({result['id']})")
    print(f"Confidence: {result['confidence_score']:.2f}")
    
    pipeline.close()

asyncio.run(main())
```

---

## âš™ï¸ Configuration Options

Key settings in `src/config.py`:

| Setting | Default | Description |
|---------|---------|-------------|
| `PIPELINE` | `"gemini"` | LLM provider: `gemini`, `ollama`, or `huggingface` |
| `CONFIDENCE_THRESHOLD` | `0.6` | Score below which synonyms are generated |
| `MAX_PIPELINE_LOOPS` | `4` | Maximum retry attempts per query |
| `DEFAULT_K_LEXICAL` | `15` | Number of lexical search results |
| `DEFAULT_K_VECTOR` | `15` | Number of vector search results |
| `MAX_CONCURRENT_REQUESTS` | `20` | Async concurrency limit for batch processing |

---

## ğŸ“Š Evaluation

Run benchmarks against standard datasets:

```bash
# Evaluate on CRAFT ChEBI
python -m src.evaluation.evaluate_craft_chebi --limit 100

# Evaluate on OpenFoodFacts
python -m src.evaluation.evaluate_on_off --limit 50

# Evaluate retriever recall
python -m src.evaluation.evaluate_retriever_recall
```

---

## ğŸ”§ LLM Backends

### Gemini (Default)
Requires `GEMINI_API_KEY` in `.env`. Uses `gemini-2.5-flash-lite` by default.

### Ollama (Local)
```bash
# Install Ollama and pull a model
ollama pull llama3.1:8b

# Update config
PIPELINE = "ollama"
```

### Hugging Face (Local GPU)
Supports quantized models with `bitsandbytes`. Configured via `HF_SELECTOR_MODEL_ID` in config.

---

## ğŸ“„ License

[Add your license here]

---

## ğŸ™ Acknowledgments

- [FoodOn](https://foodon.org/) â€” Food Ontology
- [ChEBI](https://www.ebi.ac.uk/chebi/) â€” Chemical Entities of Biological Interest
- [BioEL](https://github.com/bioel-project/bioel) â€” Biomedical Entity Linking framework
