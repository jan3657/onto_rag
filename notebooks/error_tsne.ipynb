{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354cc4dd",
   "metadata": {},
   "source": [
    "\n",
    "# Error Atlas \u2014 t-SNE Walkthrough\n",
    "\n",
    "This notebook rebuilds the error dataframe, computes query embeddings, runs PCA\u2192t-SNE, and renders interactive Plotly views. Adjust the toggles to explore all or only incorrect rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e7db7a",
   "metadata": {},
   "source": [
    "\n",
    "## Implementation Plan & Tasks (Notebook\u2011Driven)\n",
    "\n",
    "**Goal:** Extend the current t\u2011SNE analysis into a full error\u2011analysis workflow, adding taxonomy, ontology enrichment, residual embeddings, and diagnostics.\n",
    "\n",
    "### Tasks (check as you execute)\n",
    "1. [ ] Data audit: missingness, duplicates, imbalance, schema sanity\n",
    "2. [ ] Failure taxonomy: ambiguity, near\u2011miss, thresholding, retrieval vs ranking\n",
    "3. [ ] Ontology enrichment: map gold/pred IDs \u2192 labels/synonyms/definitions\n",
    "4. [ ] Multi\u2011view embeddings: query, gold, pred, residuals (q\u2212pred, q\u2212gold)\n",
    "5. [ ] 2D maps: t\u2011SNE for each view; facet by model/dataset/error_type\n",
    "6. [ ] Diagnostics: neighborhood purity, silhouette, error concentration\n",
    "7. [ ] Export: enriched parquet + plots for sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cddb36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: pip installs (uncomment if running in a fresh environment)\n",
    "# !pip install -q sentence-transformers scikit-learn plotly pandas pyarrow tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5ef8dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/jandrole/projects/onto_rag_paper_version\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "\n",
    "# --- Project root discovery (robust to running from /notebooks) ---\n",
    "\n",
    "def find_project_root(start=None, max_up=6):\n",
    "    p = Path(start or Path.cwd()).resolve()\n",
    "    for _ in range(max_up):\n",
    "        if (p / 'data').exists() and (p / 'src').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return Path.cwd().resolve()\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "ANALYSIS_DIR = DATA_DIR / 'analysis'\n",
    "EMB_DIR = DATA_DIR / 'embeddings'\n",
    "ERRORS_PATH = ANALYSIS_DIR / 'errors.parquet'\n",
    "\n",
    "encoder_name = 'intfloat/e5-small-v2'\n",
    "perplexity = 30\n",
    "pca_components = 50\n",
    "only_incorrect = True\n",
    "random_state = 42\n",
    "\n",
    "print('PROJECT_ROOT:', PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7efb0b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2566, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>gold_ids</th>\n",
       "      <th>predicted_id</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>confidence</th>\n",
       "      <th>candidate_count</th>\n",
       "      <th>candidate_labels</th>\n",
       "      <th>gold_in_candidates</th>\n",
       "      <th>gold_first_found_at_attempt</th>\n",
       "      <th>...</th>\n",
       "      <th>concurrent_requests</th>\n",
       "      <th>error_type</th>\n",
       "      <th>error</th>\n",
       "      <th>query_lower</th>\n",
       "      <th>query_len</th>\n",
       "      <th>query_tokens</th>\n",
       "      <th>query_has_digit</th>\n",
       "      <th>query_has_hyphen</th>\n",
       "      <th>query_is_upper</th>\n",
       "      <th>query_has_greek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glucose</td>\n",
       "      <td>[CHEBI:17234]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>no_prediction</td>\n",
       "      <td>None</td>\n",
       "      <td>glucose</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dipotassium phosphate</td>\n",
       "      <td>[CHEBI:32031]</td>\n",
       "      <td>CHEBI:131527</td>\n",
       "      <td>dipotassium hydrogen phosphate</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "      <td>30</td>\n",
       "      <td>[dipotassium hydrogen phosphate, dipotassium b...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>retrieval_miss</td>\n",
       "      <td>None</td>\n",
       "      <td>dipotassium phosphate</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Alizarin red</td>\n",
       "      <td>[CHEBI:16866]</td>\n",
       "      <td>CHEBI:87358</td>\n",
       "      <td>alizarin red S</td>\n",
       "      <td>False</td>\n",
       "      <td>0.85</td>\n",
       "      <td>28</td>\n",
       "      <td>[alizarin red S, alizarin, neutral red, 3,4-di...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>ranking_miss</td>\n",
       "      <td>None</td>\n",
       "      <td>alizarin red</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TAMRA</td>\n",
       "      <td>[CHEBI:51657]</td>\n",
       "      <td>CHEBI:52282</td>\n",
       "      <td>tetramethylrhodamine</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "      <td>17</td>\n",
       "      <td>[tetramethylrhodamine, 5-carboxytetramethylrho...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>ranking_miss</td>\n",
       "      <td>None</td>\n",
       "      <td>tamra</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cineol</td>\n",
       "      <td>[CHEBI:23243]</td>\n",
       "      <td>CHEBI:27961</td>\n",
       "      <td>1,8-cineole</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "      <td>22</td>\n",
       "      <td>[cineole, 1,8-cineole, 2-exo-hydroxy-1,8-cineo...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>ranking_miss</td>\n",
       "      <td>None</td>\n",
       "      <td>cineol</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    query       gold_ids  predicted_id  \\\n",
       "0                 glucose  [CHEBI:17234]          None   \n",
       "2   dipotassium phosphate  [CHEBI:32031]  CHEBI:131527   \n",
       "12           Alizarin red  [CHEBI:16866]   CHEBI:87358   \n",
       "22                  TAMRA  [CHEBI:51657]   CHEBI:52282   \n",
       "24                 cineol  [CHEBI:23243]   CHEBI:27961   \n",
       "\n",
       "                   predicted_label  is_correct  confidence  candidate_count  \\\n",
       "0                             None       False         NaN                0   \n",
       "2   dipotassium hydrogen phosphate       False        0.95               30   \n",
       "12                  alizarin red S       False        0.85               28   \n",
       "22            tetramethylrhodamine       False        0.95               17   \n",
       "24                     1,8-cineole       False        0.95               22   \n",
       "\n",
       "                                     candidate_labels  gold_in_candidates  \\\n",
       "0                                                  []               False   \n",
       "2   [dipotassium hydrogen phosphate, dipotassium b...               False   \n",
       "12  [alizarin red S, alizarin, neutral red, 3,4-di...                True   \n",
       "22  [tetramethylrhodamine, 5-carboxytetramethylrho...                True   \n",
       "24  [cineole, 1,8-cineole, 2-exo-hydroxy-1,8-cineo...                True   \n",
       "\n",
       "    gold_first_found_at_attempt  ...  concurrent_requests      error_type  \\\n",
       "0                           1.0  ...                   20   no_prediction   \n",
       "2                           NaN  ...                   20  retrieval_miss   \n",
       "12                          1.0  ...                   20    ranking_miss   \n",
       "22                          1.0  ...                   20    ranking_miss   \n",
       "24                          1.0  ...                   20    ranking_miss   \n",
       "\n",
       "   error            query_lower  query_len query_tokens query_has_digit  \\\n",
       "0   None                glucose          7            1           False   \n",
       "2   None  dipotassium phosphate         21            2           False   \n",
       "12  None           alizarin red         12            2           False   \n",
       "22  None                  tamra          5            1           False   \n",
       "24  None                 cineol          6            1           False   \n",
       "\n",
       "   query_has_hyphen query_is_upper query_has_greek  \n",
       "0             False          False           False  \n",
       "2             False          False           False  \n",
       "12            False          False           False  \n",
       "22            False           True           False  \n",
       "24            False          False           False  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load dataframe\n",
    "assert ERRORS_PATH.exists(), f\"Missing {ERRORS_PATH} \u2014 run scripts/build_error_frame.py first.\"\n",
    "df = pd.read_parquet(ERRORS_PATH)\n",
    "if only_incorrect:\n",
    "    df = df[df['is_correct'] == False].copy()\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f231edd",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Data audit & schema sanity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7974076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missingness (fraction):\n",
      "error              0.974669\n",
      "predicted_id       0.121980\n",
      "confidence         0.058067\n",
      "candidate_count    0.000000\n",
      "dtype: float64\n",
      "Top duplicates (dataset, query, gold_primary):\n",
      "dataset       query      gold_primary  \n",
      "chebi         glucose    CHEBI:17234       31\n",
      "ctd_diseases  FAP        MESH:D011125      25\n",
      "chebi         amyloid    CHEBI:60425       25\n",
      "ctd_diseases  MPS IVA    OMIM:253000       20\n",
      "ncbi_gene     STAT3      NCBIGene:6774     20\n",
      "              EGFR       NCBIGene:1956     15\n",
      "              CD82       NCBIGene:83628    15\n",
      "              IL-6       NCBIGene:3569     15\n",
      "ctd_diseases  CLD        MESH:C536210      15\n",
      "chebi         molecules  CHEBI:36357       15\n",
      "dtype: int64\n",
      "Correct/Incorrect by dataset:\n",
      "is_correct    False\n",
      "dataset            \n",
      "chebi           416\n",
      "ctd_diseases    509\n",
      "foodon          592\n",
      "ncbi_gene      1049\n",
      "Correct/Incorrect by model:\n",
      "is_correct                     False\n",
      "model                               \n",
      "DeepSeek-R1-Distill-Qwen-32B     523\n",
      "Qwen-Qwen2.5-72B-Instruct-AWQ    484\n",
      "Qwen-Qwen3-32B-AWQ               539\n",
      "gemini-2.5-flash-lite            481\n",
      "mistral_small_24b                539\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Ensure gold_ids is a list (parquet should already preserve lists)\n",
    "def ensure_list(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, tuple):\n",
    "        return list(x)\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.tolist()\n",
    "    if x is None:\n",
    "        return []\n",
    "    if isinstance(x, float) and np.isnan(x):\n",
    "        return []\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            v = ast.literal_eval(x)\n",
    "            return v if isinstance(v, list) else [v]\n",
    "        except Exception:\n",
    "            return [x]\n",
    "    return [x]\n",
    "\n",
    "_df = df.copy()\n",
    "_df['gold_ids_list'] = _df['gold_ids'].apply(ensure_list)\n",
    "\n",
    "# Missingness summary\n",
    "missing = _df[['predicted_id','confidence','error','candidate_count']].isna().mean().sort_values(ascending=False)\n",
    "print('Missingness (fraction):')\n",
    "print(missing)\n",
    "\n",
    "# Duplicate query+gold across runs\n",
    "_df['gold_primary'] = _df['gold_ids_list'].apply(lambda xs: xs[0] if xs else None)\n",
    "dup_counts = _df.groupby(['dataset','query','gold_primary']).size().sort_values(ascending=False)\n",
    "print('Top duplicates (dataset, query, gold_primary):')\n",
    "print(dup_counts.head(10))\n",
    "\n",
    "# Class balance by dataset/model\n",
    "print('Correct/Incorrect by dataset:')\n",
    "print(_df.groupby('dataset')['is_correct'].value_counts().unstack(fill_value=0))\n",
    "\n",
    "print('Correct/Incorrect by model:')\n",
    "print(_df.groupby('model')['is_correct'].value_counts().unstack(fill_value=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9ac80",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Failure taxonomy (beyond retrieval_miss/ranking_miss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c974a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failure_bucket\n",
      "retrieval_miss    1784\n",
      "ranking_miss       469\n",
      "no_prediction      248\n",
      "system_error        65\n",
      "Name: count, dtype: int64\n",
      "Ambiguity rate among incorrect: 0.3604832424006235\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Heuristic flags for ambiguity / genericity\n",
    "GENERIC_TERMS = set([\n",
    "    'molecule','molecules','compound','compounds','chemical','chemicals','substance','substances',\n",
    "    'drug','drugs','salt','salts','acid','acids','ion','ions','agent','agents','factor','factors'\n",
    "])\n",
    "\n",
    "_df['query_lower'] = _df['query'].str.lower()\n",
    "_df['is_generic'] = _df['query_lower'].isin(GENERIC_TERMS)\n",
    "_df['is_short'] = _df['query'].str.len() <= 3\n",
    "_df['is_abbrev'] = _df['query'].str.isupper() & (_df['query'].str.len() <= 6)\n",
    "\n",
    "# Failure bucket\n",
    "\n",
    "def failure_bucket(row):\n",
    "    if row['is_correct']:\n",
    "        return 'correct'\n",
    "    if row['error_type'] == 'system_error':\n",
    "        return 'system_error'\n",
    "    if row['error_type'] == 'no_prediction':\n",
    "        return 'no_prediction'\n",
    "    if row['error_type'] == 'retrieval_miss':\n",
    "        return 'retrieval_miss'\n",
    "    if row['error_type'] == 'ranking_miss':\n",
    "        return 'ranking_miss'\n",
    "    return 'other'\n",
    "\n",
    "_df['failure_bucket'] = _df.apply(failure_bucket, axis=1)\n",
    "\n",
    "# Ambiguity flags for incorrect rows\n",
    "_df['ambiguous_flag'] = (~_df['is_correct']) & (_df['is_generic'] | _df['is_abbrev'] | _df['is_short'])\n",
    "\n",
    "print(_df['failure_bucket'].value_counts())\n",
    "print('Ambiguity rate among incorrect:', _df.loc[~_df['is_correct'], 'ambiguous_flag'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09044b7",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Ontology enrichment (gold/pred \u2192 labels/synonyms/definition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e1d92",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (2003655079.py, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[35], line 41\u001b[0;36m\u001b[0m\n\u001b[0;31m    parts = line.rstrip('\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "ONTO_DUMPS = {\n",
    "    'chebi': DATA_DIR / 'chebi' / 'ontology_dump.json',\n",
    "    'ctd_diseases': DATA_DIR / 'ctd_diseases' / 'ontology_dump.json',\n",
    "    'ncbi_gene': DATA_DIR / 'ncbi_gene' / 'ontology_dump.json',\n",
    "    'foodon': DATA_DIR / 'foodon' / 'ontology_dump.json',\n",
    "}\n",
    "\n",
    "CTD_TSV = DATA_DIR / 'ontologies' / 'CTD_diseases.tsv'\n",
    "NCBI_TSV = DATA_DIR / 'ontologies' / 'gene_info.tsv'\n",
    "\n",
    "missing = [ds for ds, p in ONTO_DUMPS.items() if not p.exists()]\n",
    "if missing:\n",
    "    print('Missing ontology dumps for:', missing)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def load_ontology_dump(dataset):\n",
    "    path = ONTO_DUMPS.get(dataset)\n",
    "    if not path or not path.exists():\n",
    "        return {}\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def load_ctd_alt_map():\n",
    "    alt_map = {}\n",
    "    if not CTD_TSV.exists():\n",
    "        return alt_map\n",
    "    header = None\n",
    "    with CTD_TSV.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('# DiseaseName'):\n",
    "                header = line.lstrip('#').strip().split('\t')\n",
    "                break\n",
    "        if not header:\n",
    "            return alt_map\n",
    "        for line in f:\n",
    "            if line.startswith('#') or not line.strip():\n",
    "                continue\n",
    "            parts = line.rstrip('\n",
    "').split('\t')\n",
    "            if len(parts) != len(header):\n",
    "                continue\n",
    "            row = dict(zip(header, parts))\n",
    "            primary = row.get('DiseaseID')\n",
    "            alt_ids = row.get('AltDiseaseIDs', '')\n",
    "            if primary and alt_ids:\n",
    "                for alt in alt_ids.split('|'):\n",
    "                    alt = alt.strip()\n",
    "                    if alt:\n",
    "                        alt_map[alt] = primary\n",
    "    return alt_map\n",
    "\n",
    "\n",
    "def build_ncbi_fallback(missing_ids):\n",
    "    # Build a minimal lookup for missing NCBI Gene IDs from gene_info.tsv\n",
    "    if not missing_ids:\n",
    "        return {}\n",
    "    # normalize to bare gene ids\n",
    "    targets = set()\n",
    "    for curie in missing_ids:\n",
    "        if isinstance(curie, str) and curie.startswith('NCBIGene:'):\n",
    "            targets.add(curie.split(':', 1)[1])\n",
    "        elif isinstance(curie, str):\n",
    "            targets.add(curie)\n",
    "    if not NCBI_TSV.exists():\n",
    "        return {}\n",
    "    lookup = {}\n",
    "    with NCBI_TSV.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#') or not line.strip():\n",
    "                continue\n",
    "            parts = line.rstrip('').split('\t')\n",
    "            if len(parts) < 9:\n",
    "                continue\n",
    "            gene_id = parts[1]\n",
    "            if gene_id not in targets:\n",
    "                continue\n",
    "            symbol = parts[2]\n",
    "            synonyms = parts[4]\n",
    "            desc = parts[8] if len(parts) > 8 else ''\n",
    "            curie = f'NCBIGene:{gene_id}'\n",
    "            lookup[curie] = {\n",
    "                'label': symbol,\n",
    "                'synonyms': [s for s in synonyms.split('|') if s and s != '-'],\n",
    "                'definition': desc,\n",
    "            }\n",
    "    return lookup\n",
    "\n",
    "\n",
    "def normalize_id(dataset, curie):\n",
    "    if curie is None:\n",
    "        return None\n",
    "    # Map OMIM/DO \u2192 MESH for CTD when possible\n",
    "    if dataset == 'ctd_diseases':\n",
    "        alt_map = load_ctd_alt_map()\n",
    "        if curie in alt_map:\n",
    "            return alt_map[curie]\n",
    "    if dataset == 'ncbi_gene' and isinstance(curie, str) and curie.isdigit():\n",
    "        return f'NCBIGene:{curie}'\n",
    "    return curie\n",
    "\n",
    "\n",
    "def build_term_text(term):\n",
    "    if not term:\n",
    "        return None\n",
    "    label = term.get('label')\n",
    "    if not label:\n",
    "        return None\n",
    "    parts = [label]\n",
    "    syns = term.get('synonyms') or []\n",
    "    if syns:\n",
    "        parts.append(' ; '.join(syns[:5]))\n",
    "    definition = term.get('definition') or ''\n",
    "    if definition:\n",
    "        parts.append(definition[:200])\n",
    "    return ' | '.join(parts)\n",
    "\n",
    "# Add gold/pred labels and text\n",
    "\n",
    "def lookup_term_text(dataset, curie, fallback_label=None, ncbi_fallback=None):\n",
    "    dump = load_ontology_dump(dataset)\n",
    "    term = dump.get(curie) if curie else None\n",
    "    if term:\n",
    "        return build_term_text(term), (term.get('label') if term else None)\n",
    "    if dataset == 'ncbi_gene' and ncbi_fallback and curie in ncbi_fallback:\n",
    "        term = ncbi_fallback[curie]\n",
    "        return build_term_text(term), term.get('label')\n",
    "    if fallback_label:\n",
    "        return str(fallback_label), str(fallback_label)\n",
    "    return None, None\n",
    "\n",
    "# Normalize gold/pred IDs\n",
    "_df['gold_primary'] = _df['gold_ids_list'].apply(lambda xs: xs[0] if xs else None)\n",
    "_df['gold_primary'] = _df.apply(lambda r: normalize_id(r['dataset'], r['gold_primary']), axis=1)\n",
    "_df['predicted_id_norm'] = _df.apply(lambda r: normalize_id(r['dataset'], r['predicted_id']), axis=1)\n",
    "\n",
    "# For gold_ids, prefer any ID that exists in dump (useful for multi-ID cases)\n",
    "for ds in _df['dataset'].unique():\n",
    "    dump = load_ontology_dump(ds)\n",
    "    if not dump:\n",
    "        continue\n",
    "    mask = _df['dataset'] == ds\n",
    "    def pick_best(ids):\n",
    "        for gid in ids:\n",
    "            gid_norm = normalize_id(ds, gid)\n",
    "            if gid_norm in dump:\n",
    "                return gid_norm\n",
    "        return normalize_id(ds, ids[0]) if ids else None\n",
    "    _df.loc[mask, 'gold_primary'] = _df.loc[mask, 'gold_ids_list'].apply(pick_best)\n",
    "\n",
    "# Build NCBI fallback only for missing IDs\n",
    "ncbi_dump = load_ontology_dump('ncbi_gene')\n",
    "missing_ncbi = set(_df.loc[_df['dataset']=='ncbi_gene','gold_primary'].dropna()) - set(ncbi_dump.keys())\n",
    "if missing_ncbi:\n",
    "    print('Building NCBI fallback for', len(missing_ncbi), 'IDs')\n",
    "    ncbi_fallback = build_ncbi_fallback(missing_ncbi)\n",
    "else:\n",
    "    ncbi_fallback = {}\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "ptexts = []\n",
    "plabels = []\n",
    "\n",
    "for _, row in _df.iterrows():\n",
    "    gtext, glabel = lookup_term_text(row['dataset'], row['gold_primary'], ncbi_fallback=ncbi_fallback)\n",
    "    ptext, plabel = lookup_term_text(row['dataset'], row['predicted_id_norm'], row.get('predicted_label'), ncbi_fallback=ncbi_fallback)\n",
    "    texts.append(gtext)\n",
    "    labels.append(glabel)\n",
    "    ptexts.append(ptext)\n",
    "    plabels.append(plabel)\n",
    "\n",
    "_df['gold_text'] = texts\n",
    "_df['gold_label'] = labels\n",
    "_df['pred_text'] = ptexts\n",
    "_df['pred_label_enriched'] = plabels\n",
    "\n",
    "print('gold_text coverage:', _df['gold_text'].notna().mean())\n",
    "print('pred_text coverage:', _df['pred_text'].notna().mean())\n",
    "\n",
    "_df[['gold_primary','gold_label','predicted_id_norm','pred_label_enriched']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6befa5a3",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Multi\u2011view embeddings (query / gold / pred / residuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "ENCODER = encoder_name  # reuse from earlier cell\n",
    "\n",
    "def embed_texts(unique_texts, cache_path):\n",
    "    if cache_path.exists():\n",
    "        emb = np.load(cache_path)\n",
    "        if emb.shape[0] == len(unique_texts):\n",
    "            print(f\"Loaded {cache_path}\")\n",
    "            return emb\n",
    "    model = SentenceTransformer(ENCODER)\n",
    "    emb = model.encode(unique_texts, batch_size=64, convert_to_numpy=True,\n",
    "                       show_progress_bar=True, normalize_embeddings=True)\n",
    "    np.save(cache_path, emb)\n",
    "    print(f\"Saved {cache_path}\")\n",
    "    return emb\n",
    "\n",
    "# Build embeddings for query, gold_text, pred_text\n",
    "EMB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Query embeddings (all rows)\n",
    "q_texts = _df['query'].astype(str).tolist()\n",
    "q_unique = sorted(set(q_texts))\n",
    "q_map = {t:i for i,t in enumerate(q_unique)}\n",
    "q_cache = EMB_DIR / f\"{ENCODER.replace('/', '_')}_query.npy\"\n",
    "emb_q_unique = embed_texts(q_unique, q_cache)\n",
    "emb_q = emb_q_unique[[q_map[t] for t in q_texts]]\n",
    "\n",
    "# Gold embeddings (rows with gold_text)\n",
    "_g = _df['gold_text'].fillna('')\n",
    "_g_unique = sorted(set([t for t in _g if t]))\n",
    "g_map = {t:i for i,t in enumerate(_g_unique)}\n",
    "g_cache = EMB_DIR / f\"{ENCODER.replace('/', '_')}_gold.npy\"\n",
    "emb_g_unique = embed_texts(_g_unique, g_cache) if _g_unique else None\n",
    "\n",
    "# Pred embeddings (rows with pred_text)\n",
    "_p = _df['pred_text'].fillna('')\n",
    "_p_unique = sorted(set([t for t in _p if t]))\n",
    "p_map = {t:i for i,t in enumerate(_p_unique)}\n",
    "p_cache = EMB_DIR / f\"{ENCODER.replace('/', '_')}_pred.npy\"\n",
    "emb_p_unique = embed_texts(_p_unique, p_cache) if _p_unique else None\n",
    "\n",
    "# Build aligned arrays with NaNs for missing\n",
    "emb_g = np.full_like(emb_q, np.nan)\n",
    "emb_p = np.full_like(emb_q, np.nan)\n",
    "\n",
    "if emb_g_unique is not None:\n",
    "    for i, t in enumerate(_g):\n",
    "        if t:\n",
    "            emb_g[i] = emb_g_unique[g_map[t]]\n",
    "\n",
    "if emb_p_unique is not None:\n",
    "    for i, t in enumerate(_p):\n",
    "        if t:\n",
    "            emb_p[i] = emb_p_unique[p_map[t]]\n",
    "\n",
    "print('emb_q', emb_q.shape, 'emb_g', emb_g.shape, 'emb_p', emb_p.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64568675",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Residual embeddings + t\u2011SNE views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ba00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals: query - pred / query - gold / pred - gold\n",
    "mask_qp = ~np.isnan(emb_p).any(axis=1)\n",
    "mask_qg = ~np.isnan(emb_g).any(axis=1)\n",
    "mask_pg = mask_qp & mask_qg\n",
    "\n",
    "res_qp = emb_q[mask_qp] - emb_p[mask_qp]\n",
    "res_qg = emb_q[mask_qg] - emb_g[mask_qg]\n",
    "res_pg = emb_p[mask_pg] - emb_g[mask_pg]\n",
    "\n",
    "print('Residual shapes:', res_qp.shape, res_qg.shape, res_pg.shape)\n",
    "print('mask_qp:', mask_qp.sum(), 'mask_qg:', mask_qg.sum(), 'mask_pg:', mask_pg.sum())\n",
    "\n",
    "def run_tsne(data, perplexity=30, pca_components=50, seed=42):\n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    from sklearn.manifold import TSNE\n",
    "    if data.shape[0] < 5:\n",
    "        raise ValueError('Not enough points for t-SNE')\n",
    "    if pca_components and pca_components < data.shape[1]:\n",
    "        svd = TruncatedSVD(n_components=pca_components, random_state=seed)\n",
    "        data = svd.fit_transform(data)\n",
    "    perp = min(perplexity, max(5, data.shape[0] - 1))\n",
    "    tsne = TSNE(n_components=2, perplexity=perp, metric='cosine', init='pca',\n",
    "                random_state=seed, learning_rate='auto', max_iter=1500, verbose=1)\n",
    "    return tsne.fit_transform(data)\n",
    "\n",
    "# Choose a view to project\n",
    "view = 'q_minus_pred'  # options: q_minus_pred, q_minus_gold, pred_minus_gold\n",
    "\n",
    "# Fallback if not enough points\n",
    "if view == 'q_minus_pred' and res_qp.shape[0] < 5:\n",
    "    print('Not enough points for q_minus_pred; falling back to q_minus_gold')\n",
    "    view = 'q_minus_gold'\n",
    "if view == 'q_minus_gold' and res_qg.shape[0] < 5:\n",
    "    print('Not enough points for q_minus_gold; falling back to pred_minus_gold')\n",
    "    view = 'pred_minus_gold'\n",
    "if view == 'pred_minus_gold' and res_pg.shape[0] < 5:\n",
    "    print('Not enough points for residuals; falling back to query embeddings')\n",
    "    view = 'query'\n",
    "\n",
    "if view == 'q_minus_pred':\n",
    "    coords = run_tsne(res_qp, perplexity=30, pca_components=50)\n",
    "    df_view = _df[mask_qp].copy()\n",
    "elif view == 'q_minus_gold':\n",
    "    coords = run_tsne(res_qg, perplexity=30, pca_components=50)\n",
    "    df_view = _df[mask_qg].copy()\n",
    "elif view == 'pred_minus_gold':\n",
    "    coords = run_tsne(res_pg, perplexity=30, pca_components=50)\n",
    "    df_view = _df[mask_pg].copy()\n",
    "else:\n",
    "    coords = run_tsne(emb_q, perplexity=30, pca_components=50)\n",
    "    df_view = _df.copy()\n",
    "\n",
    "# Add coords\n",
    "_df_view = df_view.copy()\n",
    "_df_view['tsne_x'] = coords[:,0]\n",
    "_df_view['tsne_y'] = coords[:,1]\n",
    "_df_view.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f96c764",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Visualize residual space (t\u2011SNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67cc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_res = px.scatter(\n",
    "    _df_view,\n",
    "    x='tsne_x', y='tsne_y',\n",
    "    color='error_type', symbol='dataset',\n",
    "    hover_data={\n",
    "        'query': True,\n",
    "        'pred_label_enriched': True,\n",
    "        'gold_label': True,\n",
    "        'model': True,\n",
    "        'confidence': True,\n",
    "        'is_correct': True,\n",
    "        'tsne_x': False,\n",
    "        'tsne_y': False,\n",
    "    },\n",
    "    title=f\"t-SNE residual view: {view}\",\n",
    "    opacity=0.85,\n",
    ")\n",
    "fig_res.update_traces(marker=dict(size=6, line=dict(width=0)))\n",
    "fig_res.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1671f2d",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Diagnostics (cluster purity, silhouette, neighborhood hit\u2011rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98822be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Use embeddings for the CURRENT dataframe _df (may be incorrect-only)\n",
    "# Guard against NaN/inf\n",
    "finite_mask = np.isfinite(emb_q).all(axis=1)\n",
    "emb_q_finite = emb_q[finite_mask]\n",
    "_df_finite = _df.iloc[np.where(finite_mask)[0]].copy()\n",
    "\n",
    "# Neighborhood purity for error_type (current view)\n",
    "k = 15\n",
    "k = min(k, len(emb_q_finite) - 1) if len(emb_q_finite) > 1 else 1\n",
    "nbrs = NearestNeighbors(n_neighbors=k, metric='cosine').fit(emb_q_finite)\n",
    "_, idx = nbrs.kneighbors(emb_q_finite)\n",
    "\n",
    "labels = _df_finite['error_type'].astype(str).values\n",
    "purity = []\n",
    "for i, neighbors in enumerate(idx):\n",
    "    # skip self at index 0\n",
    "    neigh_labels = labels[neighbors[1:]] if len(neighbors) > 1 else labels[neighbors]\n",
    "    purity.append((neigh_labels == labels[i]).mean())\n",
    "\n",
    "_df_finite['nn_purity_error_type'] = purity\n",
    "print('Avg neighborhood purity (error_type):', _df_finite['nn_purity_error_type'].mean())\n",
    "\n",
    "# Silhouette score by error_type (exclude tiny classes)\n",
    "label_counts = _df_finite['error_type'].value_counts()\n",
    "valid = _df_finite['error_type'].isin(label_counts[label_counts > 10].index)\n",
    "try:\n",
    "    if valid.sum() > 10:\n",
    "        sil = silhouette_score(emb_q_finite[valid], _df_finite.loc[valid, 'error_type'])\n",
    "        print('Silhouette (error_type):', sil)\n",
    "    else:\n",
    "        print('Silhouette skipped: not enough samples after filtering')\n",
    "except Exception as e:\n",
    "    print('Silhouette failed:', e)\n",
    "\n",
    "# Error rates should be computed on FULL dataset, not filtered\n",
    "_df_full = pd.read_parquet(ERRORS_PATH)\n",
    "\n",
    "print('\n",
    "Accuracy by dataset (full):')\n",
    "print((_df_full.groupby('dataset')['is_correct'].mean().rename('accuracy')))\n",
    "\n",
    "print('\n",
    "Accuracy by model (full):')\n",
    "print((_df_full.groupby('model')['is_correct'].mean().rename('accuracy')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7623cd5",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Export enriched dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff3b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export enriched dataframe\n",
    "ANALYSIS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "out_path = ANALYSIS_DIR / 'errors_enriched.parquet'\n",
    "_df.to_parquet(out_path, index=False)\n",
    "print('Wrote', out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e01b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper: encode unique texts with caching on disk\n",
    "import hashlib\n",
    "\n",
    "def cache_path_for(encoder: str):\n",
    "    slug = encoder.replace('/', '_').replace(':', '_')\n",
    "    return EMB_DIR / f\"{slug}_query_embeddings.npy\"\n",
    "\n",
    "EMB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "cache_path = cache_path_for(encoder_name)\n",
    "\n",
    "texts = df['query'].astype(str).tolist()\n",
    "unique_texts = sorted(set(texts))\n",
    "text_to_idx = {t: i for i, t in enumerate(unique_texts)}\n",
    "\n",
    "if cache_path.exists():\n",
    "    emb_unique = np.load(cache_path)\n",
    "    if emb_unique.shape[0] != len(unique_texts):\n",
    "        print('Cache size mismatch; recomputing embeddings...')\n",
    "        emb_unique = None\n",
    "else:\n",
    "    emb_unique = None\n",
    "\n",
    "if emb_unique is None:\n",
    "    model = SentenceTransformer(encoder_name)\n",
    "    emb_unique = model.encode(unique_texts, batch_size=64, convert_to_numpy=True,\n",
    "                              show_progress_bar=True, normalize_embeddings=True)\n",
    "    np.save(cache_path, emb_unique)\n",
    "    print(f\"Saved embeddings to {cache_path}\")\n",
    "else:\n",
    "    print(f\"Loaded embeddings from {cache_path}\")\n",
    "\n",
    "emb_full = emb_unique[[text_to_idx[t] for t in texts]]\n",
    "emb_full.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PCA (SVD) before t-SNE for speed/stability\n",
    "svd = TruncatedSVD(n_components=min(pca_components, emb_full.shape[1]-1), random_state=random_state)\n",
    "emb_svd = svd.fit_transform(emb_full)\n",
    "emb_svd.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# t-SNE projection\n",
    "perp = min(perplexity, max(5, len(df) - 1))\n",
    "tsne = TSNE(n_components=2, perplexity=perp, metric='cosine', init='pca',\n",
    "            random_state=random_state, learning_rate='auto', max_iter=1500, verbose=1)\n",
    "coords = tsne.fit_transform(emb_svd)\n",
    "df_plot = df.copy()\n",
    "df_plot['tsne_x'] = coords[:,0]\n",
    "df_plot['tsne_y'] = coords[:,1]\n",
    "coords[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faac7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Interactive scatter\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x='tsne_x', y='tsne_y',\n",
    "    color='error_type', symbol='dataset',\n",
    "    hover_data={\n",
    "        'query': True,\n",
    "        'predicted_label': True,\n",
    "        'gold_ids': True,\n",
    "        'model': True,\n",
    "        'run_id': True,\n",
    "        'confidence': True,\n",
    "        'is_correct': True,\n",
    "        'tsne_x': False,\n",
    "        'tsne_y': False,\n",
    "    },\n",
    "    title=f\"t-SNE of queries (encoder={encoder_name}, perplexity={perp})\",\n",
    "    opacity=0.85,\n",
    ")\n",
    "fig.update_traces(marker=dict(size=6, line=dict(width=0)))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78939fcd",
   "metadata": {},
   "source": [
    "\n",
    "## Explore neighborhoods\n",
    "Pick a query and see its nearest neighbors in embedding space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e203df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute cosine similarity vs all points for an example query\n",
    "example_query = df_plot.iloc[0]['query']\n",
    "q_idx = df_plot.index[df_plot['query'] == example_query][0]\n",
    "q_vec = emb_full[q_idx]\n",
    "\n",
    "# use dot product because vectors are normalized\n",
    "sims = emb_full @ q_vec\n",
    "nn_idx = sims.argsort()[::-1][:15]\n",
    "\n",
    "nn = df_plot.iloc[nn_idx][['query','error_type','dataset','model','confidence','predicted_label','gold_ids']]\n",
    "print(f\"Example query: {example_query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f443f7b2",
   "metadata": {},
   "source": [
    "\n",
    "## By model / dataset faceting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06706b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_facet = px.scatter(\n",
    "    df_plot,\n",
    "    x='tsne_x', y='tsne_y',\n",
    "    color='error_type',\n",
    "    facet_col='dataset', facet_row='model',\n",
    "    height=900,\n",
    "    width=1400,\n",
    "    opacity=0.8,\n",
    "    title='t-SNE faceted by dataset/model',\n",
    ")\n",
    "fig_facet.update_traces(marker=dict(size=4, line=dict(width=0)))\n",
    "fig_facet.update_annotations(textangle=0)\n",
    "for annotation in fig_facet.layout.annotations:\n",
    "    if 'model=' in annotation.text:\n",
    "        annotation.textangle = 80\n",
    "fig_facet.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onto_rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}